{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "722a26dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T15:56:09.635881Z",
     "iopub.status.busy": "2025-11-01T15:56:09.635677Z",
     "iopub.status.idle": "2025-11-01T15:56:26.611405Z",
     "shell.execute_reply": "2025-11-01T15:56:26.610817Z"
    },
    "papermill": {
     "duration": 16.980368,
     "end_time": "2025-11-01T15:56:26.612915",
     "exception": false,
     "start_time": "2025-11-01T15:56:09.632547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 15:56:11.640778: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762012571.881746      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762012571.955410      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D,Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2d9e309",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T15:56:26.618102Z",
     "iopub.status.busy": "2025-11-01T15:56:26.617682Z",
     "iopub.status.idle": "2025-11-01T15:56:26.621600Z",
     "shell.execute_reply": "2025-11-01T15:56:26.620843Z"
    },
    "papermill": {
     "duration": 0.007774,
     "end_time": "2025-11-01T15:56:26.623005",
     "exception": false,
     "start_time": "2025-11-01T15:56:26.615231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range = 0.1,\n",
    "    rotation_range = 15,\n",
    "    horizontal_flip = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37ac94e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T15:56:26.627583Z",
     "iopub.status.busy": "2025-11-01T15:56:26.627318Z",
     "iopub.status.idle": "2025-11-01T15:56:28.534946Z",
     "shell.execute_reply": "2025-11-01T15:56:28.534187Z"
    },
    "papermill": {
     "duration": 1.911327,
     "end_time": "2025-11-01T15:56:28.536281",
     "exception": false,
     "start_time": "2025-11-01T15:56:26.624954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 636 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train = data.flow_from_directory(\n",
    "    '/kaggle/input/eggs-images-classification-damaged-or-not/Eggs Classification',\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary',\n",
    "    subset = 'training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1fea258",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T15:56:28.541337Z",
     "iopub.status.busy": "2025-11-01T15:56:28.541111Z",
     "iopub.status.idle": "2025-11-01T15:56:28.554861Z",
     "shell.execute_reply": "2025-11-01T15:56:28.554304Z"
    },
    "papermill": {
     "duration": 0.017376,
     "end_time": "2025-11-01T15:56:28.555868",
     "exception": false,
     "start_time": "2025-11-01T15:56:28.538492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 158 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test = data.flow_from_directory(\n",
    "    '/kaggle/input/eggs-images-classification-damaged-or-not/Eggs Classification',\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02e94745",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T15:56:28.560536Z",
     "iopub.status.busy": "2025-11-01T15:56:28.560313Z",
     "iopub.status.idle": "2025-11-01T15:56:29.651255Z",
     "shell.execute_reply": "2025-11-01T15:56:29.650388Z"
    },
    "papermill": {
     "duration": 1.094679,
     "end_time": "2025-11-01T15:56:29.652513",
     "exception": false,
     "start_time": "2025-11-01T15:56:28.557834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762012589.608357      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1762012589.609057      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential(\n",
    "    [\n",
    "        \n",
    "        layers.Conv2D(32,(3,3),activation = 'relu'),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "\n",
    "        layers.Conv2D(64,(3,3),activation = 'relu'),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "\n",
    "        layers.Conv2D(128,(3,3),activation = 'relu'),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "\n",
    "        layers.Dense(256,activation = 'relu'),\n",
    "\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1,activation='sigmoid')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cf6166d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T15:56:29.657755Z",
     "iopub.status.busy": "2025-11-01T15:56:29.657321Z",
     "iopub.status.idle": "2025-11-01T15:56:29.679044Z",
     "shell.execute_reply": "2025-11-01T15:56:29.678248Z"
    },
    "papermill": {
     "duration": 0.025467,
     "end_time": "2025-11-01T15:56:29.680182",
     "exception": false,
     "start_time": "2025-11-01T15:56:29.654715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#compile\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1757f264",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T15:56:29.687037Z",
     "iopub.status.busy": "2025-11-01T15:56:29.686704Z",
     "iopub.status.idle": "2025-11-01T16:00:01.305907Z",
     "shell.execute_reply": "2025-11-01T16:00:01.305329Z"
    },
    "papermill": {
     "duration": 211.624458,
     "end_time": "2025-11-01T16:00:01.307094",
     "exception": false,
     "start_time": "2025-11-01T15:56:29.682636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762012596.671297      75 service.cc:148] XLA service 0x7c021c0040c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1762012596.672046      75 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1762012596.672069      75 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1762012597.142721      75 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 2/20\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6562 - loss: 77.3780"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762012602.552931      75 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.6493 - loss: 122.8392 - val_accuracy: 0.7975 - val_loss: 0.5220\n",
      "Epoch 2/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 960ms/step - accuracy: 0.7925 - loss: 0.4664 - val_accuracy: 0.7975 - val_loss: 0.5127\n",
      "Epoch 3/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 963ms/step - accuracy: 0.8261 - loss: 0.4569 - val_accuracy: 0.8038 - val_loss: 0.4665\n",
      "Epoch 4/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 971ms/step - accuracy: 0.7954 - loss: 0.4357 - val_accuracy: 0.8038 - val_loss: 0.5383\n",
      "Epoch 5/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 960ms/step - accuracy: 0.8193 - loss: 0.4092 - val_accuracy: 0.7975 - val_loss: 0.7339\n",
      "Epoch 6/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 956ms/step - accuracy: 0.8095 - loss: 0.3907 - val_accuracy: 0.7975 - val_loss: 0.5286\n",
      "Epoch 7/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 963ms/step - accuracy: 0.8216 - loss: 0.3517 - val_accuracy: 0.8165 - val_loss: 0.4194\n",
      "Epoch 8/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 949ms/step - accuracy: 0.8184 - loss: 0.4731 - val_accuracy: 0.7848 - val_loss: 0.5560\n",
      "Epoch 9/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 948ms/step - accuracy: 0.8029 - loss: 0.4691 - val_accuracy: 0.7975 - val_loss: 0.5923\n",
      "Epoch 10/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 967ms/step - accuracy: 0.8063 - loss: 0.4922 - val_accuracy: 0.7975 - val_loss: 0.4809\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "training = model.fit(\n",
    "    train,validation_data = test,epochs = 10 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f1c9b29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T16:00:01.330086Z",
     "iopub.status.busy": "2025-11-01T16:00:01.329856Z",
     "iopub.status.idle": "2025-11-01T16:00:01.342907Z",
     "shell.execute_reply": "2025-11-01T16:00:01.342194Z"
    },
    "papermill": {
     "duration": 0.025526,
     "end_time": "2025-11-01T16:00:01.343979",
     "exception": false,
     "start_time": "2025-11-01T16:00:01.318453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Damaged: 632 samples, 79.60%\n",
      "Not Damaged: 162 samples, 20.40%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root = '/kaggle/input/eggs-images-classification-damaged-or-not/Eggs Classification'   # chứa các folder lớp\n",
    "folders = [d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))]\n",
    "counts = {}\n",
    "total = 0\n",
    "for f in folders:\n",
    "    n = len([name for name in os.listdir(os.path.join(root, f)) \n",
    "             if os.path.isfile(os.path.join(root, f, name))])\n",
    "    counts[f] = n\n",
    "    total += n\n",
    "\n",
    "for k, v in counts.items():\n",
    "    print(f\"{k}: {v} samples, {v/total*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa58718d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T16:00:01.365967Z",
     "iopub.status.busy": "2025-11-01T16:00:01.365782Z",
     "iopub.status.idle": "2025-11-01T16:05:06.820879Z",
     "shell.execute_reply": "2025-11-01T16:05:06.819972Z"
    },
    "papermill": {
     "duration": 305.477786,
     "end_time": "2025-11-01T16:05:06.832540",
     "exception": false,
     "start_time": "2025-11-01T16:00:01.354754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 636 images belonging to 2 classes.\n",
      "Found 158 images belonging to 2 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Epoch 1/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 4s/step - accuracy: 0.7184 - loss: 1.0985 - val_accuracy: 0.7975 - val_loss: 0.8877\n",
      "Epoch 2/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 989ms/step - accuracy: 0.7636 - loss: 0.8906 - val_accuracy: 0.7975 - val_loss: 0.8165\n",
      "Epoch 3/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.7983 - loss: 0.7337 - val_accuracy: 0.7975 - val_loss: 0.8028\n",
      "Epoch 4/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.7757 - loss: 0.7255 - val_accuracy: 0.8418 - val_loss: 0.7541\n",
      "Epoch 5/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.8612 - loss: 0.5575 - val_accuracy: 0.8038 - val_loss: 0.6273\n",
      "Epoch 6/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9229 - loss: 0.4394 - val_accuracy: 0.6835 - val_loss: 0.7252\n",
      "Epoch 7/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.7849 - loss: 0.6015 - val_accuracy: 0.8291 - val_loss: 0.6478\n",
      "Epoch 8/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9173 - loss: 0.4161 - val_accuracy: 0.8291 - val_loss: 0.7571\n",
      "Epoch 9/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9463 - loss: 0.3388 - val_accuracy: 0.8544 - val_loss: 0.5110\n",
      "Epoch 10/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9411 - loss: 0.3250 - val_accuracy: 0.8797 - val_loss: 0.4825\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "data = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train = data.flow_from_directory(\n",
    "    '/kaggle/input/eggs-images-classification-damaged-or-not/Eggs Classification',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val = data.flow_from_directory(\n",
    "    '/kaggle/input/eggs-images-classification-damaged-or-not/Eggs Classification',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=val,\n",
    "    epochs=10\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4361124,
     "sourceId": 7490549,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 544.189257,
   "end_time": "2025-11-01T16:05:10.049651",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-01T15:56:05.860394",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
